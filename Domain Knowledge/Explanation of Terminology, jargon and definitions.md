# 3.Explanation of Terminology, jargon and definitions
de volgende begrippen zijn all belangrijke en relevante terminologie, jargon en defienties van datascience. Voor deze begrippen heb ik deze [bron](http://www.datascienceglossary.org/) gebruikt. 


#### Data Science:

Een interdisciplinair onderzoeksveld met betrekking tot wetenschappelijke methoden, processen en systemen om kennis en inzichten te onttrekken uit (zowel gestructureerde als ongestructureerde) data . 

#### Overfitting:

Het model volgt de data te nauw. In plaats van een beschrijving van de echte trends, is het model een product van de eigenaardigheden. 

#### Underfitting:

Underfitting, vindt plaats zodra het model niet complex genoeg is om de relatie tussen de gebruikte features en de voorspelde waarde in kaart te brengen. 

#### Generalisatie:

Het vereenvoudigen van data-beeld en data-inhoud, rekening houdend met het doel en de schaal van de data.

#### Regression:

Techniek om de grote lijn te vinden in een hoeveelheid gegevens. Grafisch wordt dit meestal uitgebeeld door het trekken van een lijn die de meeste punten zoveel mogelijk benadert (Encylco). 

#### Correlation:

Statistisch begrip voor de samenhang tussen twee verschijnselen, twee variabelen. Een hoge correlatie betekent dat beide verschijnselen relatief vaak samen voorkomen. Maar niet dat de ene de oorzaak van de andere is.

#### Machine learning:

Een breed onderzoeksveld binnen kunstmatige intelligentie, dat zich bezighoudt met de ontwikkeling van algoritmes en technieken waarmee computers kunnen leren (Machinaal leren, n.d.). 

#### Neurale netwerken:

Neurale netwerken vormen een belangrijke aanpak in machine learning. Deze netwerken zijn samengesteld uit veelvoudige maar eenvoudige processoren die parallel werken om (niet-lineaire) systemen te modelleren, waar een complexe relatie bestaat tussen input en output.

#### Classification:

Classificatie is een begeleid machine learning-probleem. Het behandelt het categoriseren van een datapunt op basis van de gelijkenis met andere datapunten. Je neemt een set gegevens waarvan elk item al een categorie heeft en kijkt naar gemeenschappelijke kenmerken tussen elk item. Vervolgens gebruik je die gemeenschappelijke kenmerken als richtlijn voor welke categorie het nieuwe item zou kunnen hebben.

#### Training en testen:

Dit maakt deel uit van de machine learning-workflow. Wanneer u een voorspellend model maakt, biedt u het eerst een set trainingsgegevens aan, zodat het begrip kan opbouwen. Vervolgens geef je het model een testset, waar het zijn begrip toepast en probeert een doelwaarde te voorspellen.

#### Data Analysis:

Deze discipline is het kleine broertje van data science. Data-analyse is meer gericht op het beantwoorden van vragen over heden en verleden. Het gebruikt minder complexe statistieken en probeert over het algemeen patronen te identificeren die een organisatie kunnen verbeteren.
Data Engineering

#### Algoritmen:

Een algoritme is een reeks instructies die we een computer geven zodat deze waarden kan aannemen en deze in een bruikbare vorm kan manipuleren. Dit kan zo eenvoudig zijn als het vinden en verwijderen van elke komma in een alinea.

#### Data engineering:

Bij data-engineering draait alles om de achterkant. Dit zijn de mensen die systemen bouwen om het voor datawetenschappers gemakkelijk te maken om hun analyses uit te voeren. In kleinere teams kan een datawetenschapper ook een data-engineer zijn. In grotere groepen kunnen ingenieurs zich uitsluitend concentreren op het versnellen van de analyse en het goed georganiseerd en gemakkelijk toegankelijk houden van gegevens.

#### Data Visualization:

De kunst van het visueel communiceren van betekenisvolle gegevens. Dit kunnen infographics, traditionele plots of zelfs volledige datadashboards zijn.

#### Mean (Average, Expected Value):

Een berekening die ons een idee geeft van een "typische" waarde voor een groep getallen. Het gemiddelde is de som van een lijst met waarden gedeeld door het aantal waarden in die lijst. Het kan op zichzelf al misleidend zijn, en in de praktijk gebruiken we het gemiddelde met andere statistische waarden om intuïtie te krijgen over onze gegevens.

#### Median:

In een reeks waarden die in volgorde worden vermeld, is de mediaan de waarde in het midden. We gebruiken vaak de mediaan samen met het gemiddelde om te beoordelen of er waarden zijn die ongebruikelijk hoog of laag zijn in de set. Dit is een vroege hint om uitschieters te onderzoeken.

#### Time Series:

Een tijdreeks is een set gegevens die is gesorteerd op het moment waarop elk gegevenspunt optrad. Denk aan de beurskoersen in de loop van een maand, of de temperatuur gedurende een dag.

#### Residual (Error):

Het residual is een maatstaf voor hoeveel een werkelijke waarde verschilt van een of andere statische waarde die we hebben berekend op basis van de set gegevens. Dus gezien een voorspelling dat het morgen om 12.00 uur 20 graden Fahrenheit zal zijn, als het middag is en het slechts 18 graden is, hebben we een fout van 2 graden. Dit wordt vaak door elkaar gebruikt met de term "fout", ook al is fout technisch gezien een puur theoretische waarde

#### Variance:

De variantie van een reeks waarden meet hoe verspreid die waarden zijn. Wiskundig gezien is het gemiddelde verschil tussen individuele waarden en het gemiddelde voor de reeks waarden. De vierkantswortel van de variantie voor een set geeft ons de standaarddeviatie, die intuïtiever bruikbaar is.

#### Data Exploration:

Het deel van het data science-proces waarbij een wetenschapper basisvragen stelt die haar helpen de context van een dataset te begrijpen. Wat u tijdens de verkenningsfase leert, zal later leiden tot een meer diepgaande analyse. Verder helpt het u te herkennen wanneer een resultaat verrassend kan zijn en nader onderzoek rechtvaardigt.

#### Feature Engineering:

Het proces van het nemen van kennis die we als mens hebben en het vertalen naar een kwantitatieve waarde die een computer kan begrijpen. We kunnen bijvoorbeeld ons visuele begrip van de afbeelding van een mok vertalen naar een weergave van pixelintensiteiten.

#### Feature Selection:

Het proces om te bepalen welke eigenschappen van een dataset het meest waardevol zullen zijn bij het bouwen van een model. Het is vooral handig bij grote datasets, omdat het gebruik van minder functies de hoeveelheid tijd en complexiteit vermindert die nodig is om een model te trainen en te testen. Het proces begint met het meten van hoe relevant elk kenmerk in een dataset is voor het voorspellen van uw doelvariabele. U kiest vervolgens een subset van functies die zullen leiden tot een krachtig model.

#### Supervised Machine Learning:

Met begeleide leertechnieken geeft de datawetenschapper de computer een goed gedefinieerde set gegevens. Alle kolommen zijn gelabeld en de computer weet precies waarnaar hij zoekt. Het is vergelijkbaar met een professor die je een syllabus geeft en je vertelt wat je tijdens de finale kunt verwachten.

#### Unsupervised Machine Learning:

Bij leertechnieken zonder toezicht bouwt de computer zijn eigen begrip op van een reeks niet-gelabelde gegevens. Ongecontroleerde ML-technieken zoeken naar patronen in gegevens en hebben vaak te maken met het classificeren van items op basis van gedeelde kenmerken.

#### Python:

Python is een programmeertaal die de afgelopen jaren erg populair is geworden bij datawetenschappers vanwege het relatieve gebruiksgemak en de geavanceerde manieren waarop het kan worden gebruikt om met grote, snel bewegende datasets te werken. De open source (iedereen kan eraan toevoegen of veranderen) betekent dat de mogelijkheden voortdurend worden uitgebreid en dat er nieuwe bronnen beschikbaar komen.

#### Panda's:

Een open-source softwarebibliotheek voor Python. 



